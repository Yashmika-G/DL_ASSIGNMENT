{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKScB69UTxP_",
        "outputId": "921d1db9-5daf-4a5a-ec88-2c8479fcd5e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "import numpy as np\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "def load_and_preprocess_image(img_path):\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array = preprocess_input(img_array)\n",
        "    return img_array\n",
        "\n",
        "def classify_image(img_path):\n",
        "    img_array = load_and_preprocess_image(img_path)\n",
        "    preds = model.predict(img_array)\n",
        "    decoded_preds = decode_predictions(preds, top=5)[0]\n",
        "    return decoded_preds\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    img_path = '/content/istockphoto-1420676204-612x612.jpg'\n",
        "    predictions = classify_image(img_path)\n",
        "\n",
        "    print(\"Predictions:\")\n",
        "    for i, (imagenet_id, label, score) in enumerate(predictions):\n",
        "        print(f\"{i + 1}: {label} ({score:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blHQz7QdVlL3",
        "outputId": "bf8acc88-fb83-4060-9815-8ac95f313b37"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels.h5\n",
            "\u001b[1m102967424/102967424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "\u001b[1m35363/35363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Predictions:\n",
            "1: tiger (0.78)\n",
            "2: tiger_cat (0.19)\n",
            "3: zebra (0.01)\n",
            "4: jaguar (0.01)\n",
            "5: tabby (0.00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define Text Encoder (simple LSTM for text to feature vector)\n",
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text_input):\n",
        "        x = self.embedding(text_input)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = lstm_out[:, -1, :]  # Use the last LSTM output\n",
        "        text_features = self.fc(lstm_out)\n",
        "        return text_features\n",
        "\n",
        "# Define the Generator (Simple CNN + ResNet as feature extractor)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, text_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim + text_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 512)\n",
        "        self.fc4 = nn.Linear(512, 3 * 64 * 64)  # Assuming image size 64x64\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.resnet.eval()  # Freeze ResNet\n",
        "\n",
        "    def forward(self, z, text_features):\n",
        "        x = torch.cat((z, text_features), dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = x.view(-1, 3, 64, 64)  # Reshape to image dimensions\n",
        "        return x\n",
        "\n",
        "# Define Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.fc = nn.Linear(128*16*16, 1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = F.relu(self.conv1(img))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x\n",
        "\n",
        "# Load and preprocess the text input\n",
        "def preprocess_text(text, vocab):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    token_indices = [vocab[word] if word in vocab else vocab['<UNK>'] for word in tokens]\n",
        "    return torch.tensor(token_indices).unsqueeze(0)  # Shape: (1, sequence_length)\n",
        "\n",
        "# Initialize models\n",
        "z_dim = 100\n",
        "text_dim = 256  # Embedding size of the text\n",
        "vocab = {'<UNK>': 0, 'dog': 1, 'running': 2, 'field': 3}  # Simple vocabulary for illustration\n",
        "\n",
        "text_encoder = TextEncoder(input_dim=len(vocab), embedding_dim=128, hidden_dim=256, output_dim=text_dim)\n",
        "generator = Generator(z_dim=z_dim, text_dim=text_dim)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Define loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Train the GAN (simplified loop)\n",
        "def train_gan(num_epochs=100):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Generate random noise\n",
        "        z = torch.randn(16, z_dim)\n",
        "\n",
        "        # Preprocess a sample text input\n",
        "        text_input = preprocess_text(\"A dog running in a field\", vocab)\n",
        "        text_features = text_encoder(text_input)\n",
        "\n",
        "        # Generate fake image\n",
        "        fake_img = generator(z, text_features)\n",
        "\n",
        "        # Discriminator forward pass\n",
        "        real_img = torch.randn(16, 3, 64, 64)  # Dummy real image (replace with real data)\n",
        "        real_labels = torch.ones(16, 1)\n",
        "        fake_labels = torch.zeros(16, 1)\n",
        "\n",
        "        real_preds = discriminator(real_img)\n",
        "        fake_preds = discriminator(fake_img.detach())\n",
        "\n",
        "        # Compute discriminator loss\n",
        "        d_loss_real = criterion(real_preds, real_labels)\n",
        "        d_loss_fake = criterion(fake_preds, fake_labels)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # Update Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Generator forward pass\n",
        "        fake_preds = discriminator(fake_img)\n",
        "        g_loss = criterion(fake_preds, real_labels)\n",
        "\n",
        "        # Update Generator\n",
        "        optimizer_g.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
        "\n",
        "# Training the model\n",
        "train_gan(num_epochs=100)\n",
        "\n",
        "# Generate and display an image\n",
        "def generate_and_display_image(text_input):\n",
        "    z = torch.randn(1, z_dim)\n",
        "    text_input = preprocess_text(text_input, vocab)\n",
        "    text_features = text_encoder(text_input)\n",
        "    generated_img = generator(z, text_features)\n",
        "    generated_img = generated_img.squeeze().detach().numpy().transpose(1, 2, 0)\n",
        "\n",
        "    plt.imshow((generated_img + 1) / 2)  # Rescale to [0, 1] for display\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Generate and display an image from the description\n",
        "generate_and_display_image(\"A dog running in a field\")\n"
      ],
      "metadata": {
        "id": "1W3Wq-xuUKfG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "outputId": "2e39d04c-7d16-4be5-fc36-a6a206c8dd86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 135MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "LookupError",
          "evalue": "\n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-3416d8068ee1>\u001b[0m in \u001b[0;36m<cell line: 127>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;31m# Training the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m \u001b[0mtrain_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;31m# Generate and display an image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-3416d8068ee1>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(num_epochs)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;31m# Preprocess a sample text input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mtext_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A dog running in a field\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m         \u001b[0mtext_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-3416d8068ee1>\u001b[0m in \u001b[0;36mpreprocess_text\u001b[0;34m(text, vocab)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Load and preprocess the text input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0mtoken_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocab\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<UNK>'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Shape: (1, sequence_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36mword_tokenize\u001b[0;34m(text, language, preserve_line)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mtype\u001b[0m \u001b[0mpreserve_line\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \"\"\"\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpreserve_line\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m     return [\n\u001b[1;32m    131\u001b[0m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_treebank_word_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/tokenize/__init__.py\u001b[0m in \u001b[0;36msent_tokenize\u001b[0;34m(text, language)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m \u001b[0mlanguage\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mPunkt\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \"\"\"\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"tokenizers/punkt/{language}.pickle\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(resource_url, format, cache, verbose, logic_parser, fstruct_reader, encoding)\u001b[0m\n\u001b[1;32m    748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;31m# Load the resource.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m     \u001b[0mopened_resource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raw\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(resource_url)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprotocol\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"nltk\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 876\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    877\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"file\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# urllib might not use mode='rb', so handle this one ourselves:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mpunkt\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('punkt')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mtokenizers/punkt/PY3/english.pickle\u001b[0m\n\n  Searched in:\n    - '/root/nltk_data'\n    - '/usr/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n    - ''\n**********************************************************************\n"
          ]
        }
      ]
    },
    {
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torchvision.transforms import ToTensor\n",
        "from nltk.tokenize import word_tokenize # This line uses the downloaded 'punkt' resource\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ... (rest of the code remains the same) ..."
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iX2OXNaauHVm",
        "outputId": "1a715259-b592-4950-e0ef-689bc71b09ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.5)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super(TextEncoder, self).__init__()\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, text_input):\n",
        "        x = self.embedding(text_input)\n",
        "        lstm_out, _ = self.lstm(x)\n",
        "        lstm_out = lstm_out[:, -1, :]  # Use the last LSTM output\n",
        "        text_features = self.fc(lstm_out)\n",
        "        return text_features\n",
        "\n",
        "# Define the Generator (Simple CNN + ResNet as feature extractor)\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, text_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.fc1 = nn.Linear(z_dim + text_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 512)\n",
        "        self.fc4 = nn.Linear(512, 3 * 64 * 64)  # Assuming image size 64x64\n",
        "        self.resnet = models.resnet18(pretrained=True)\n",
        "        self.resnet.eval()  # Freeze ResNet\n",
        "\n",
        "    def forward(self, z, text_features):\n",
        "        x = torch.cat((z, text_features), dim=1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        x = x.view(-1, 3, 64, 64)  # Reshape to image dimensions\n",
        "        return x\n",
        "\n",
        "# Define Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1)\n",
        "        self.fc = nn.Linear(128*16*16, 1)\n",
        "\n",
        "    def forward(self, img):\n",
        "        x = F.relu(self.conv1(img))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
        "        x = torch.sigmoid(self.fc(x))\n",
        "        return x\n",
        "\n",
        "# Load and preprocess the text input\n",
        "def preprocess_text(text, vocab):\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    token_indices = [vocab[word] if word in vocab else vocab['<UNK>'] for word in tokens]\n",
        "    return torch.tensor(token_indices).unsqueeze(0)  # Shape: (1, sequence_length)\n",
        "\n",
        "# Initialize models\n",
        "z_dim = 100\n",
        "text_dim = 256  # Embedding size of the text\n",
        "vocab = {'<UNK>': 0, 'dog': 1, 'running': 2, 'field': 3}  # Simple vocabulary for illustration\n",
        "\n",
        "text_encoder = TextEncoder(input_dim=len(vocab), embedding_dim=128, hidden_dim=256, output_dim=text_dim)\n",
        "generator = Generator(z_dim=z_dim, text_dim=text_dim)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Define loss and optimizers\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Train the GAN (simplified loop)\n",
        "def train_gan(num_epochs=100):\n",
        "    for epoch in range(num_epochs):\n",
        "        # Generate random noise\n",
        "        z = torch.randn(16, z_dim)\n",
        "\n",
        "        # Preprocess a sample text input\n",
        "        # Preprocess a sample text input and repeat it 16 times\n",
        "        text_input = preprocess_text(\"A dog running in a field\", vocab).repeat(16, 1)\n",
        "        text_features = text_encoder(text_input)\n",
        "\n",
        "        # Generate fake image\n",
        "        fake_img = generator(z, text_features)\n",
        "\n",
        "        # Discriminator forward pass\n",
        "        real_img = torch.randn(16, 3, 64, 64)  # Dummy real image (replace with real data)\n",
        "        real_labels = torch.ones(16, 1)\n",
        "        fake_labels = torch.zeros(16, 1)\n",
        "\n",
        "        real_preds = discriminator(real_img)\n",
        "        fake_preds = discriminator(fake_img.detach())\n",
        "\n",
        "        # Compute discriminator loss\n",
        "        d_loss_real = criterion(real_preds, real_labels)\n",
        "        d_loss_fake = criterion(fake_preds, fake_labels)\n",
        "        d_loss = d_loss_real + d_loss_fake\n",
        "\n",
        "        # Update Discriminator\n",
        "        optimizer_d.zero_grad()\n",
        "        d_loss.backward()\n",
        "        optimizer_d.step()\n",
        "\n",
        "        # Generator forward pass\n",
        "        fake_preds = discriminator(fake_img)\n",
        "        g_loss = criterion(fake_preds, real_labels)\n",
        "\n",
        "        # Update Generator\n",
        "        optimizer_g.zero_grad()\n",
        "        g_loss.backward()\n",
        "        optimizer_g.step()\n",
        "\n",
        "        if epoch % 10 == 0:\n",
        "            print(f\"Epoch [{epoch}/{num_epochs}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")\n",
        "\n",
        "# Training the model\n",
        "train_gan(num_epochs=100)\n",
        "\n",
        "# Generate and display an image\n",
        "def generate_and_display_image(text_input):\n",
        "    z = torch.randn(1, z_dim)\n",
        "    text_input = preprocess_text(text_input, vocab)\n",
        "    text_features = text_encoder(text_input)\n",
        "    generated_img = generator(z, text_features)\n",
        "    generated_img = generated_img.squeeze().detach().numpy().transpose(1, 2, 0)\n",
        "\n",
        "    plt.imshow((generated_img + 1) / 2)  # Rescale to [0, 1] for display\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Generate and display an image from the description\n",
        "generate_and_display_image(\"A dog running in a field\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "w3WPtY_gt4Ko",
        "outputId": "dd92f000-9c16-4b00-fc0a-b5a5c072622a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [0/100], D Loss: 1.3800688982009888, G Loss: 0.6412832140922546\n",
            "Epoch [10/100], D Loss: 0.737414538860321, G Loss: 0.7447198033332825\n",
            "Epoch [20/100], D Loss: 0.7211605310440063, G Loss: 0.938181459903717\n",
            "Epoch [30/100], D Loss: 0.6556885838508606, G Loss: 2.565380334854126\n",
            "Epoch [40/100], D Loss: 0.56329745054245, G Loss: 3.096609592437744\n",
            "Epoch [50/100], D Loss: 0.5567864775657654, G Loss: 1.9136241674423218\n",
            "Epoch [60/100], D Loss: 0.7046070694923401, G Loss: 1.6607329845428467\n",
            "Epoch [70/100], D Loss: 0.8473727107048035, G Loss: 2.127779722213745\n",
            "Epoch [80/100], D Loss: 1.3761518001556396, G Loss: 2.71968936920166\n",
            "Epoch [90/100], D Loss: 0.9445952773094177, G Loss: 1.6355621814727783\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BpzolKqYuV3Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}